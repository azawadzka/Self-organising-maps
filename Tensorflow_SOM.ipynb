{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow - SOM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5KbquAJAn94",
        "colab_type": "text"
      },
      "source": [
        "#### Sources\n",
        "https://www.researchgate.net/publication/236027587_Hierarchical_Color_Quantization_Based_on_Self-organization\n",
        "\n",
        "http://blog.yhat.com/posts/self-organizing-maps-2.html\n",
        "\n",
        "https://visualstudiomagazine.com/articles/2019/01/01/self-organizing-maps-python.aspx\n",
        "\n",
        "https://rubikscode.net/2018/08/27/implementing-self-organizing-maps-with-python-and-tensorflow/\n",
        "\n",
        "https://github.com/JustGlowing/minisom\n",
        "\n",
        "https://medium.com/machine-learning-researcher/self-organizing-map-som-c296561e2117\n",
        "\n",
        "https://github.com/davidasboth/blog-notebooks/blob/master/self-organising-map/Self-Organising%20Map.ipynb\n",
        "\n",
        "https://github.com/davidasboth/blog-notebooks/blob/master/self-organising-map/Self-Organising%20Map.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzlaeavyB6Hh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab3ffee5-33dc-4d88-ff8f-f76a3a979411"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3PAAyKJSNlA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9366c8ce-0122-48a5-c373-deadf115de5e"
      },
      "source": [
        "Input = tf.placeholder(dtype='float', shape=[None, 2], name='Input')\n",
        "weights = tf.Variable(initial_value=tf.random_normal(shape=[2,3], stddev=0.4, dtype='float', name='hiddenweights'))\n",
        "input_bias = tf.Variable(initial_value=tf.random_normal(shape=[3], stddev=0.4, dtype='float', name='inputbias'))\n",
        "hidden_bias = tf.Variable(initial_value=tf.random_normal(shape=[1], stddev=0.4, dtype='float', name='hiddenbias'))\n",
        "output = tf.Variable(initial_value=tf.random_normal(shape=[3, 1], stddev=0.4, dtype='float', name='outputweights'))\n",
        "Target = tf.placeholder(dtype='float', shape=[None, 1], name='Target')\n",
        "\n",
        "hiddenLayer = tf.matmul(Input, weights) + input_bias\n",
        "hiddenLayer = tf.sigmoid(hiddenLayer, name='hidden_layer_activaction')\n",
        "\n",
        "outputLayer = tf.matmul(hiddenLayer, output) + hidden_bias\n",
        "outputLayer = tf.sigmoid(outputLayer, name='output_layer_activaction')\n",
        "\n",
        "cost = tf.squared_difference(Target, outputLayer) \n",
        "cost = tf.reduce_mean(cost)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "\n",
        "inp = [[1.,1.], [1.,0.], [0.,1.], [0.,0.]]\n",
        "out = [[0], [1], [1], [0]]\n",
        "epochs = 4000\n",
        "\n",
        "with tf.Session() as session:\n",
        "  tf.global_variables_initializer().run()\n",
        "  for i in range(epochs):\n",
        "    err, _ = session.run([cost, optimizer], feed_dict={Input: inp, Target: out})\n",
        "    print(i, err)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMjZhRa9dprg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86fff8ed-3897-4a9d-de03-bf6f578df5b8"
      },
      "source": [
        "# SOM\n",
        "input_matrix = [[0.,0.,1.,1.], [1.,0.,0.,0.]]\n",
        "data_size = [2,4]\n",
        "epochs = 10\n",
        "\n",
        "learning_rate = tf.Variable(0.5)\n",
        "input_data = tf.placeholder(dtype='float', shape=[None, data_size[1]], name='input_data')\n",
        "weights = tf.Variable(initial_value=tf.random_normal(shape=[data_size[1], data_size[0]], stddev=0.4, dtype='float', name='weights'))\n",
        "ROW = tf.placeholder(dtype='float', shape=[data_size[1]], name='ROW')\n",
        "input_vector = tf.transpose(ROW)\n",
        "tile = tf.reshape(tf.tile(input_vector, [data_size[0]]), [data_size[1], data_size[0]])\n",
        "squared_diff = tf.squared_difference(weights, tile) # squared difference itemwise\n",
        "d = tf.math.reduce_sum(squared_diff, axis=0) # sum along axis 0\n",
        "closest_sum_index = tf.math.argmax(d) # choose smallest squared difference sum along columns\n",
        "updated_col = weights[:,closest_sum_index] + learning_rate * (input_vector - weights[:,closest_sum_index]) # create updated vector\n",
        "update_weights = weights[:,closest_sum_index].assign(updated_col) # update weights\n",
        "\n",
        "with tf.Session() as session:\n",
        "  tf.global_variables_initializer().run()\n",
        "  data = session.run(input_data, {input_data: input_matrix})\n",
        "  for _ in range(epochs):\n",
        "    for row in data:\n",
        "      session.run(update_weights, {ROW: row})\n",
        "      print(weights.eval())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.2233635   0.6293827 ]\n",
            " [ 0.3241031   0.18949364]\n",
            " [ 0.27314147  0.57103515]\n",
            " [-0.18833636  0.15753645]]\n",
            "[[ 0.38831824  0.6293827 ]\n",
            " [ 0.16205154  0.18949364]\n",
            " [ 0.13657074  0.57103515]\n",
            " [-0.09416818  0.15753645]]\n",
            "[[ 0.38831824  0.31469136]\n",
            " [ 0.16205154  0.09474682]\n",
            " [ 0.13657074  0.7855176 ]\n",
            " [-0.09416818  0.57876825]]\n",
            "[[ 0.69415915  0.31469136]\n",
            " [ 0.08102577  0.09474682]\n",
            " [ 0.06828537  0.7855176 ]\n",
            " [-0.04708409  0.57876825]]\n",
            "[[0.34707958 0.31469136]\n",
            " [0.04051289 0.09474682]\n",
            " [0.5341427  0.7855176 ]\n",
            " [0.47645795 0.57876825]]\n",
            "[[0.34707958 0.65734565]\n",
            " [0.04051289 0.04737341]\n",
            " [0.5341427  0.3927588 ]\n",
            " [0.47645795 0.28938413]]\n",
            "[[0.34707958 0.32867283]\n",
            " [0.04051289 0.02368671]\n",
            " [0.5341427  0.6963794 ]\n",
            " [0.47645795 0.64469206]]\n",
            "[[0.34707958 0.66433644]\n",
            " [0.04051289 0.01184335]\n",
            " [0.5341427  0.3481897 ]\n",
            " [0.47645795 0.32234603]]\n",
            "[[0.34707958 0.33216822]\n",
            " [0.04051289 0.00592168]\n",
            " [0.5341427  0.67409486]\n",
            " [0.47645795 0.661173  ]]\n",
            "[[0.34707958 0.6660841 ]\n",
            " [0.04051289 0.00296084]\n",
            " [0.5341427  0.33704743]\n",
            " [0.47645795 0.3305865 ]]\n",
            "[[0.34707958 0.33304206]\n",
            " [0.04051289 0.00148042]\n",
            " [0.5341427  0.66852367]\n",
            " [0.47645795 0.6652932 ]]\n",
            "[[0.34707958 0.6665211 ]\n",
            " [0.04051289 0.00074021]\n",
            " [0.5341427  0.33426183]\n",
            " [0.47645795 0.3326466 ]]\n",
            "[[3.4707958e-01 3.3326054e-01]\n",
            " [4.0512886e-02 3.7010477e-04]\n",
            " [5.3414267e-01 6.6713095e-01]\n",
            " [4.7645795e-01 6.6632330e-01]]\n",
            "[[3.4707958e-01 6.6663027e-01]\n",
            " [4.0512886e-02 1.8505238e-04]\n",
            " [5.3414267e-01 3.3356547e-01]\n",
            " [4.7645795e-01 3.3316165e-01]]\n",
            "[[3.4707958e-01 3.3331513e-01]\n",
            " [4.0512886e-02 9.2526192e-05]\n",
            " [5.3414267e-01 6.6678274e-01]\n",
            " [4.7645795e-01 6.6658080e-01]]\n",
            "[[3.4707958e-01 6.6665757e-01]\n",
            " [4.0512886e-02 4.6263096e-05]\n",
            " [5.3414267e-01 3.3339137e-01]\n",
            " [4.7645795e-01 3.3329040e-01]]\n",
            "[[3.4707958e-01 3.3332878e-01]\n",
            " [4.0512886e-02 2.3131548e-05]\n",
            " [5.3414267e-01 6.6669571e-01]\n",
            " [4.7645795e-01 6.6664517e-01]]\n",
            "[[3.4707958e-01 6.6666436e-01]\n",
            " [4.0512886e-02 1.1565774e-05]\n",
            " [5.3414267e-01 3.3334786e-01]\n",
            " [4.7645795e-01 3.3332258e-01]]\n",
            "[[3.4707958e-01 3.3333218e-01]\n",
            " [4.0512886e-02 5.7828870e-06]\n",
            " [5.3414267e-01 6.6667390e-01]\n",
            " [4.7645795e-01 6.6666126e-01]]\n",
            "[[3.4707958e-01 6.6666609e-01]\n",
            " [4.0512886e-02 2.8914435e-06]\n",
            " [5.3414267e-01 3.3333695e-01]\n",
            " [4.7645795e-01 3.3333063e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QAXheMHUpuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SOM 3D\n",
        "input_matrix = np.matrix([[0.,0.,1.,1.], [1.,0.,0.,0.], [1.,0.,0.,0.]], dtype=tf.float64)\n",
        "map_dimension = [5,6]\n",
        "data_size = [3,4]\n",
        "t = tf.Variable(1, dtype=tf.int64)\n",
        "learning_rate = tf.Variable(0.5, dtype=tf.float64)\n",
        "input_data = tf.placeholder(dtype=tf.float64, shape=[None, 4])\n",
        "weights = tf.Variable(initial_value=tf.random_normal(shape=[4, 5, 6], stddev=0.4, dtype=tf.float64, seed=0))\n",
        "input_vector = input_data[0,:]\n",
        "input_vector_3d = tf.expand_dims(tf.expand_dims(input_vector, [1]), [1])\n",
        "input_vector_multiplied = tf.tile(input_vector_3d, [1,5,6])\n",
        "squared_diff = tf.squared_difference(weights, input_vector_multiplied)\n",
        "distances = tf.math.reduce_sum(squared_diff, axis=0) # Euclidean distances but skip sqrt\n",
        "closest_sum_indices = tf.transpose(tf.where(tf.equal(tf.math.reduce_min(distances), distances)))\n",
        "closest_sum_weights_3d = tf.expand_dims(closest_sum_indices, [1])\n",
        "closest_sum_weights_multiplied = tf.tile(closest_sum_weights_3d, [1,5,6])\n",
        "\n",
        "ind1 = tf.expand_dims(tf.tile(tf.expand_dims(tf.range(5), [1]), [1,6]), [0])\n",
        "ind2 = tf.expand_dims(tf.transpose(tf.tile(tf.expand_dims(tf.range(6), [1]), [1,5])), [0])\n",
        "output_indices = tf.concat([ind1, ind2], axis=0)\n",
        "output_weights = tf.math.reduce_sum(tf.squared_difference(tf.cast(closest_sum_weights_multiplied, tf.float64), tf.cast(output_indices, tf.float64)), axis=0)\n",
        "delta = tf.cast(t, tf.float64)\n",
        "neighbourhood = tf.math.exp(-output_weights/(2*delta*delta))\n",
        "neighbourhood_3d = tf.expand_dims(neighbourhood, 0)\n",
        "neighbourhood_multiplied = tf.tile(neighbourhood_3d, [4,1,1])\n",
        "\n",
        "new_weights = weights.assign(weights - learning_rate * delta * neighbourhood * (input_vector_multiplied - weights))\n",
        "\n",
        "with tf.Session() as session:\n",
        "  tf.global_variables_initializer().run()\n",
        "\n",
        "  print(session.run(squared_diff, {input_data: input_matrix}))\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yGBsOmf3G4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6d6607c4-8edb-4d0c-8c89-5d6aca6c0288"
      },
      "source": [
        "# SOM 3D\n",
        "input_matrix = [[0.,0.,1.,1.], [1.,0.,0.,0.], [1.,0.,0.,0.]]\n",
        "map_dimension = [5,6]\n",
        "data_size = [3,4]\n",
        "epochs = 1\n",
        "t = tf.Variable(1, dtype=tf.int64)\n",
        "t_increment = t.assign(t+1)\n",
        "learning_rate = tf.Variable(0.5, dtype=tf.float64)\n",
        "input_data = tf.placeholder(dtype=tf.float64, shape=[None, 4])\n",
        "shuffle = tf.random.shuffle(input_data)\n",
        "weights = tf.Variable(initial_value=tf.random_normal(shape=[4, 5, 6], stddev=0.4, dtype=tf.float64, seed=0))\n",
        "ROW = tf.placeholder(dtype=tf.float64, shape=[data_size[1]])\n",
        "input_vector = ROW\n",
        "input_vector_3d = tf.expand_dims(tf.expand_dims(input_vector, [1]), [1])\n",
        "squared_diff = tf.squared_difference(weights, input_vector_3d)\n",
        "distances = tf.math.reduce_sum(squared_diff, axis=0) # Euclidean distances but skip sqrt\n",
        "closest_sum_indices = tf.transpose(tf.where(tf.equal(tf.math.reduce_min(distances), distances)))\n",
        "closest_sum_weights_3d = tf.expand_dims(closest_sum_indices, [1])\n",
        "\n",
        "ind1 = tf.expand_dims(tf.tile(tf.expand_dims(tf.range(5), [1]), [1,6]), [0])\n",
        "ind2 = tf.expand_dims(tf.transpose(tf.tile(tf.expand_dims(tf.range(6), [1]), [1,5])), [0])\n",
        "output_indices = tf.concat([ind1, ind2], axis=0)\n",
        "output_weights = tf.math.reduce_sum(tf.squared_difference(tf.cast(closest_sum_weights_3d, tf.float64), tf.cast(output_indices, tf.float64)), axis=0)\n",
        "delta = tf.cast(t, tf.float64)\n",
        "neighbourhood = tf.math.exp(-output_weights/(2*delta*delta))\n",
        "neighbourhood_3d = tf.expand_dims(neighbourhood, 0)\n",
        "\n",
        "update_weights = weights.assign(weights - learning_rate * delta * neighbourhood_3d * (input_vector_3d - weights))\n",
        "\n",
        "out_distances = tf.math.reduce_sum(tf.squared_difference(input_vector_3d, weights), axis=0)\n",
        "winner_indices = tf.squeeze(tf.where(tf.equal(tf.math.reduce_min(out_distances), out_distances))) # for one row\n",
        "\n",
        "with tf.Session() as session:\n",
        "  tf.global_variables_initializer().run()\n",
        "  \n",
        "  for _ in range(epochs):\n",
        "    data = session.run(shuffle, {input_data: input_matrix})\n",
        "    for row in data:\n",
        "      session.run(update_weights, {ROW: row})\n",
        "      session.run(t_increment)\n",
        "  \n",
        "\n",
        "  winners = np.empty([data_size[0],2], dtype=int)\n",
        "  data = session.run(input_data, {input_data: input_matrix})\n",
        "  for i, row in enumerate(data):\n",
        "    winners[i] = session.run(winner_indices, {ROW: row})\n",
        "  print(winners)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4 0]\n",
            " [0 5]\n",
            " [0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g1fCL1EmUIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SOM 3D\n",
        "input_matrix = [[0.,0.,1.,1.,0.], [1.,0.,0.,0., 0.], [1.,0.,0.,0.,0.]]\n",
        "map_dimension = [30,30]\n",
        "data_size = [3,5]\n",
        "epochs = 1\n",
        "\n",
        "t = tf.Variable(1, dtype=tf.int64)\n",
        "t_increment = t.assign(t+1)\n",
        "learning_rate = tf.Variable(0.5, dtype=tf.float64)\n",
        "input_data = tf.placeholder(dtype=tf.float64, shape=[None, data_size[1]])\n",
        "shuffle = tf.random.shuffle(input_data)\n",
        "weights = tf.Variable(initial_value=tf.random_normal(shape=[data_size[1], map_dimension[0], map_dimension[1]], stddev=0.4, dtype=tf.float64, seed=0))\n",
        "ROW = tf.placeholder(dtype=tf.float64, shape=[data_size[1]])\n",
        "\n",
        "input_vector = ROW\n",
        "input_vector_3d = tf.expand_dims(tf.expand_dims(input_vector, [1]), [2])\n",
        "squared_diff = tf.squared_difference(weights, input_vector_3d)\n",
        "distances = tf.math.reduce_sum(squared_diff, axis=0) # Euclidean distances but skip sqrt\n",
        "closest_sum_indices = tf.transpose(tf.where(tf.equal(tf.math.reduce_min(distances), distances)))\n",
        "closest_sum_weights_3d = tf.expand_dims(closest_sum_indices, [1])\n",
        "\n",
        "ind1 = tf.expand_dims(tf.tile(tf.expand_dims(tf.range(map_dimension[0]), [1]), [1, map_dimension[1]]), [0])\n",
        "ind2 = tf.expand_dims(tf.transpose(tf.tile(tf.expand_dims(tf.range(map_dimension[1]), [1]), [1,map_dimension[0]])), [0])\n",
        "output_indices = tf.concat([ind1, ind2], axis=0)\n",
        "output_weights = tf.math.reduce_sum(tf.squared_difference(tf.cast(closest_sum_weights_3d, tf.float64), tf.cast(output_indices, tf.float64)), axis=0)\n",
        "delta = tf.cast(t, tf.float64)\n",
        "neighbourhood = tf.math.exp(-output_weights/(2*delta*delta))\n",
        "neighbourhood_3d = tf.expand_dims(neighbourhood, 0)\n",
        "update_weights = weights.assign(weights - learning_rate * delta * neighbourhood_3d * (input_vector_3d - weights))\n",
        "\n",
        "out_distances = tf.math.reduce_sum(tf.squared_difference(input_vector_3d, weights), axis=0)\n",
        "winner_indices = tf.squeeze(tf.where(tf.equal(tf.math.reduce_min(out_distances), out_distances))) # for one row\n",
        "\n",
        "\n",
        "with tf.Session() as session:\n",
        "  tf.global_variables_initializer().run()\n",
        "\n",
        "  for _ in range(epochs):\n",
        "    data = session.run(shuffle, {input_data: input_matrix})\n",
        "    #print(session.run(output_weights))\n",
        "    for row in data:\n",
        "      session.run(update_weights, {ROW: row})\n",
        "      session.run(t_increment)\n",
        "  \n",
        "\n",
        "  winners = np.empty([data_size[0],2], dtype=int)\n",
        "  data = session.run(input_data, {input_data: input_matrix})\n",
        "  for i, row in enumerate(data):\n",
        "    winners[i] = session.run(winner_indices, {ROW: row})\n",
        "  print(winners)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
